{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Example 1 - TensorRt.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1luZHwozPXbM8VadLZ0uW7LIdbYPgWG5R","authorship_tag":"ABX9TyMjxlzMf9khjlKD/ItY+GF+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dKxYktxhMd8_"},"source":["# Install TensorRt and Torch2TRT on Google Colab. You have to restart the notebook for change to take effect. Ignore this part on Jetbot."]},{"cell_type":"markdown","metadata":{"id":"HlWJhWaOUDe2"},"source":["### Install TensorRt\r\n","1. Create new folder 'TRT' on Google drive\r\n","2. Download deb package for cuda 10 and place into TRT folder\r\n","3. Run script below"]},{"cell_type":"markdown","metadata":{"id":"wa4yUnWJNCxH"},"source":["### Download \r\n","https://developer.nvidia.com/compute/machine-learning/tensorrt/secure/7.0/7.0.0.11/local_repo/nv-tensorrt-repo-ubuntu1804-cuda10.0-trt7.0.0.11-ga-20191216_1-1_amd64.deb and place it in your google drive under a folder \"TRT\"."]},{"cell_type":"code","metadata":{"id":"hE_KtOnxMcc0"},"source":["import os\r\n","os.environ[\"os1\"]=\"ubuntu1804\"\r\n","os.environ[\"tag\"]=\"cuda10.0-trt7.0.0.11-ga-20191216\"\r\n","os.environ[\"version\"]=\"7.0.0-1+cuda10.0\"\r\n","os.chdir('/content/drive/MyDrive/TRT/')\r\n","!sudo dpkg -i nv-tensorrt-repo-${os1}-${tag}_1-1_amd64.deb\r\n","!sudo apt-key add /var/nv-tensorrt-repo-${tag}/7fa2af80.pub\r\n","!sudo apt-get update\r\n","!sudo apt-get install libnvinfer7=${version} libnvonnxparsers7=${version} libnvparsers7=${version} libnvinfer-plugin7=${version} libnvinfer-dev=${version} libnvonnxparsers-dev=${version} libnvparsers-dev=${version} libnvinfer-plugin-dev=${version} python-libnvinfer=${version} python3-libnvinfer=${version}\r\n","!sudo apt-mark hold libnvinfer7 libnvonnxparsers7 libnvparsers7 libnvinfer-plugin7 libnvinfer-dev libnvonnxparsers-dev libnvparsers-dev libnvinfer-plugin-dev python-libnvinfer python3-libnvinfer\r\n","!sudo apt-get install tensorrt=${version}\r\n","!sudo apt-get install python3-libnvinfer-dev=${version}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G4OufK6LUlK_"},"source":["### Install torch2trt\r\n","1. Create folder 'torch2trt' on Google drive\r\n","2. Run script below\r\n","3. Restart the notebook after installation success"]},{"cell_type":"code","metadata":{"id":"HQMPDu1YKyaH"},"source":["!git clone https://github.com/NVIDIA-AI-IOT/torch2trt /drive/MyDrive/torch2trt\r\n","! cd /drive/MyDrive/torch2trt && pwd && python setup.py install"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ElCVNh-YRB7s"},"source":["# Convert PyTorch model using torch2trt"]},{"cell_type":"code","metadata":{"id":"UC_WTOgsYEm_"},"source":["import os\r\n","import time\r\n","\r\n","# Helper function to get size\r\n","def get_size(file_path):\r\n","    b = os.path.getsize(file_path)\r\n","    print(\"File size in byte: \", b)\r\n","\r\n","# Helper function to measure inference time and return model predictions\r\n","def run_inference(model, data):\r\n","    t0 = time.time()\r\n","    output = model(data)\r\n","    print(\"Inference Speed (s): {:.4f}\".format(time.time() - t0))\r\n","\r\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c4aWYuveVDaS"},"source":["Use a pretrained resnet50 model from torchvision for example. Set to eval to change layer behavior to inference because we only want to use it for inference"]},{"cell_type":"code","metadata":{"id":"LizSSk4FXWsQ"},"source":["import torchvision\r\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vEmR4u_VnIv"},"source":["model = torchvision.models.resnet50(pretrained=True).cuda().eval()\r\n","\r\n","model_path = '/content/drive/MyDrive/JetBot/Day 4/Examples/resnet50.pth'\r\n","# model_path = 'resnet50.pth' # Use this on Jetbot\r\n","torch.save(model.state_dict(), model_path)\r\n","get_size(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQO4HXt7WMXt"},"source":["for name, param in model.state_dict().items():\r\n","    print(\"Layer: \", name)\r\n","    print(param.type())\r\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgqIFDpoVtAC"},"source":["# model = model.half()\r\n","\r\n","# for name, param in model.state_dict().items():\r\n","#     print(\"Layer: \", name)\r\n","#     print(param.type())\r\n","#     break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JJFmO8TlVQxq"},"source":["Next, create some sample input that will be used to infer the shape and data types of our TensorRT engine\r\n","\r\n","Make sure to set the right shape for input according to the model input shape."]},{"cell_type":"code","metadata":{"id":"zNu7H4nTKV1A"},"source":["data = torch.randn((1, 3, 224, 224)).cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-lU_DwEKZ2U"},"source":["# If you encounter ModuleNotFoundError: No module named 'torch2trt' on Google Colab, restart the session\r\n","from torch2trt import torch2trt\r\n","\r\n","model_trt = torch2trt(model, [data], fp16_mode=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oTv46ecnXZ3d"},"source":["Perform inference using converted model"]},{"cell_type":"code","metadata":{"id":"XDnhNzgiKdUZ"},"source":["output_trt = run_inference(model_trt, data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Cpjl5B3dbzN"},"source":["output = run_inference(model, data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YXUHsHuHd025"},"source":["# Check predictions error of both model"]},{"cell_type":"code","metadata":{"id":"l2rYZCgzTFfM"},"source":["print('max error: %f' % float(torch.max(torch.abs(output - output_trt))))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nRQWVNv9eq-f"},"source":["### Check the size of trt model"]},{"cell_type":"code","metadata":{"id":"w4a4M4tiTPOd"},"source":["model_path = '/content/drive/MyDrive/JetBot/Day 4/Examples/resnet50_trt.pth'\r\n","# model_path = 'resnet50_trt.pth' # Use this on Jetbot\r\n","\r\n","torch.save(model_trt.state_dict(), model_path)\r\n","\r\n","get_size(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W-lojtNugGfJ"},"source":["67358703 > 102549933"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7uf62yYUU9OD"},"source":["# Load tensorrt model"]},{"cell_type":"code","metadata":{"id":"5pA8YkEhT1wW"},"source":["from torch2trt import TRTModule\r\n","\r\n","model_trt = TRTModule()\r\n","\r\n","model_path = '/content/drive/MyDrive/JetBot/Day 4/Examples/resnet50_trt.pth'\r\n","# model_path = 'resnet50_trt.pth' # Use this on Jetbot\r\n","\r\n","model_trt.load_state_dict(torch.load(model_path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-66RaFkNk9tL"},"source":[""],"execution_count":null,"outputs":[]}]}