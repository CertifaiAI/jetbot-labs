{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Following and Collision Avoidance\n",
    "\n",
    "In this notebook we will use the models we trained on both Road Following and Collision Avoidance so that our robot will be able to follow the track and avoid collisions at the same time!\n",
    "\n",
    "Before starting let's first upload our trained models *best_steering_model_xy_trt.pth* and *best_collision_model.pth* into this file directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the TRT optimized model for both Road Following and Collision Avoidance by executing the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('best_steering_model_xy_trt.pth'))\n",
    "\n",
    "model_trt_collision = TRTModule()\n",
    "model_trt_collision.load_state_dict(torch.load('best_collision_model_trt.pth')) # anti collision model trained for one object as blocked and street as free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the preprocessing function\n",
    "\n",
    "We have now loaded our model, but there's a slight issue.  The format that we trained our model doesnt *exactly* match the format of the camera.  To do that, \n",
    "we need to do some *preprocessing*.  This involves the following steps\n",
    "\n",
    "1. Convert from HWC layout to CHW layout\n",
    "2. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "3. Transfer the data from CPU memory to GPU memory\n",
    "4. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We've now defined our pre-processing function which can convert images from the camera format to the neural network input format.\n",
    "\n",
    "Now, let's start and display our camera. You should be pretty familiar with this by now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera=Camera.instance(width=224, height=224,fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create our robot instance which we'll need to drive the motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define sliders to control the JetBot, **Blocked slider** to see the probability that the robot is blocked, **Stoptime slider** to select maually the time-for-stop when object has been detected and lastly **Blocked threshold** slider to manually set the threshold for when to stop depending on the blocked probability\n",
    ".\n",
    "\n",
    "1. Speed Control (speed_gain_slider): To start your JetBot increase ``speed_gain_slider`` \n",
    "2. Steering Gain Control (steering_gain_sloder): If you see JetBot is woblling, you need to reduce ``steering_gain_slider`` till it is smooth\n",
    "3. Steering Bias control (steering_bias_slider): If you see JetBot is biased towards extreme right or extreme left side of the track, you should control this slider till JetBot start following line or track in the center.  This accounts for motor biases as well as camera offsets\n",
    "\n",
    "> Note: You should play around above mentioned sliders with lower speed to get smooth JetBot road following behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f34e7910466468690a77631527c44fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c937acdf60408399bc5bef914d7781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.1, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f95a5768b44d6fbb905de0da2e7bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.23, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47853f51e13d4719a8bc43807c581b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38685259841c4eafa0a8a7e47a2c4c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='blocked', max=1.0), FloatSlider(value=0.8, description='bloâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Road Following\n",
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.10, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.23, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)\n",
    "\n",
    "#Collision Avoidance\n",
    "blocked_slider = ipywidgets.FloatSlider(description='blocked', min=0.0, max=1.0)\n",
    "stoptime_slider= ipywidgets.IntSlider(description='time to stop', min=1, max=100, step=1, value=10) \n",
    "blocked_threshold= ipywidgets.FloatSlider(description='blocked threshold', min=0, max=1.0, step=0.01, value=0.8)\n",
    "\n",
    "#display(image_widget)\n",
    "\n",
    "display(ipywidgets.HBox([blocked_slider, blocked_threshold, stoptime_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a function that will get called whenever the camera's value changes. This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Execute the neural network\n",
    "3. Compute the approximate steering value\n",
    "4. Control the motors using proportional / derivative control (PD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "go_on=1\n",
    "count_stops=0\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, go_on, count_stops\n",
    "    \n",
    "    image = change['new']\n",
    "    image_preprocessed = preprocess(image)\n",
    "    \n",
    "    #Collsion Avoidance\n",
    "    y_collision = model_trt_collision(image_preprocessed)\n",
    "    \n",
    "    #We apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y_collison = F.softmax(y_collison) #F.softmax(y_collison, dim=1) \n",
    "    \n",
    "    prob_blocked = float(y_collison.flatten()[0])\n",
    "    blocked_slider.value = prob_blocked\n",
    "    \n",
    "    if go_on==1:\n",
    "        if prob_blocked > block_threshold.value:\n",
    "            speed_slider.value=0.0\n",
    "            go_on=2\n",
    "        else:\n",
    "            #start of road following\n",
    "            count_stops=0\n",
    "            xy = model_trt(image_preprocessed).detach().float().cpu().numpy().flatten()\n",
    "            x = xy[0]\n",
    "            y = (0.5 - xy[1]) / 2.0\n",
    "    else:\n",
    "        count_stops += 1\n",
    "        if count_stops<stop_time:\n",
    "            x=0.0 #set steering zero\n",
    "            y=0.0 #set steering zero\n",
    "            speed_gain_slider.value=0 #set speed zero\n",
    "        else:\n",
    "            go_on=1\n",
    "            count_stops=0\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "    \n",
    "    robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0)*0.88, 0.0)\n",
    "    robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We've created our neural network execution function, but now we need to attach it to the camera for processing.\n",
    "\n",
    "We accomplish that with the observe function.\n",
    "\n",
    "> WARNING: This code will move the robot!! Please make sure your robot has clearance.  The Road Following and Collision Avoidance should work, but the neural\n",
    "> network is only as good as the data it's trained on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! If your robot is plugged in it should now be generating new commands with each new camera frame. Try placing your robot on the track and see whether it is able to follow the track and try placing an object which you have trained in the collision avoidance and see whether the robot stops. \n",
    "\n",
    "If you want to stop the Jetbot and unattach the camera execute the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "That's it for this live demo! Hopefully you had some fun seeing your robot move smoothly across the track as well as avoid collisions!\n",
    "\n",
    "If your robot wasn't following the road very well or wasn't avoiding collisions properly, try to spot where it fails. The beauty is that we can collect more data for these failure scenarios and the JetBot should get even better :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
