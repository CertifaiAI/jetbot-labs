{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5OW4csoRjXr"
   },
   "source": [
    "# Part 2 - Classification with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WcjqDImRf87"
   },
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10LsEe7QhMRP"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e051WsvWPb9k"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\r\n",
    "n_epochs = 10\r\n",
    "batch_size_train = 128\r\n",
    "batch_size_test = 32\r\n",
    "learning_rate = 0.01\r\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beixi1tJOX2U"
   },
   "source": [
    "## Prepare FashionMNIST image dataset\r\n",
    "\r\n",
    "Using torchvision api to download MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFOUrJxwXsJi"
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\r\n",
    "        torchvision.transforms.ToTensor()\r\n",
    "    ])\r\n",
    "\r\n",
    "train_data = torchvision.datasets.FashionMNIST('./data', train=True, download=True,\r\n",
    "                                       transform=transform)\r\n",
    "validation_data = torchvision.datasets.FashionMNIST('./data', train=False, download=True,\r\n",
    "                                      transform=transform)\r\n",
    "\r\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size_train, \r\n",
    "                                           shuffle=True)\r\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size_test, \r\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQaNIp60ObkF"
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQrG4ScyYtoo"
   },
   "outputs": [],
   "source": [
    "class Net():\r\n",
    "    pass\r\n",
    "    \"\"\"\r\n",
    "    Define CNN model according to details below\r\n",
    "    1. 2 Convolution layers named conv1 and conv2\r\n",
    "        - conv1 = 10 output channels, kernel size of 5 by 5\r\n",
    "        - conv2 = 20 output channels, kernel size of 5 by 5\r\n",
    "    2. 2 Fully connected layers fc1 and fc2\r\n",
    "        - fc1 = 50 output features\r\n",
    "        - fc2 = Output layer\r\n",
    "    \"\"\"\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MhwUtzyOWgY"
   },
   "outputs": [],
   "source": [
    "# Initialize model and send to GPU\r\n",
    "network = Net().to(device)\r\n",
    "\r\n",
    "# Set algorithm for parameter update\r\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_F7M1hJOeDy"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnBwAdMxZ6Mu"
   },
   "outputs": [],
   "source": [
    "def evaluate():\r\n",
    "    \"\"\"\r\n",
    "    Build evaluation loop\r\n",
    "    \"\"\" \r\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwQGFw0-1JLn"
   },
   "outputs": [],
   "source": [
    "train_losses, train_counter, val_losses = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQttClGbaOrh"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, n_epochs + 1):\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    Build Training Loop\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Perform evaluation\r\n",
    "    evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r93dTMK3PM4r"
   },
   "source": [
    "## View Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5MByWx0aUJ6"
   },
   "outputs": [],
   "source": [
    "# Evaluate on one batch only\r\n",
    "examples = enumerate(validation_loader)\r\n",
    "batch_idx, (example_data, example_targets) = next(examples)\r\n",
    "\r\n",
    "# To run model without performing grading parameters\r\n",
    "with torch.no_grad():\r\n",
    "\r\n",
    "    # Prepare dataset\r\n",
    "    pred_data = example_data\r\n",
    "\r\n",
    "    # Set model to evaluation mode\r\n",
    "    network.eval()\r\n",
    "\r\n",
    "    # Inference\r\n",
    "    predictions = network(pred_data.to(device))\r\n",
    "\r\n",
    "    # Format predictions to get labels\r\n",
    "    predicted_labels = predictions.data.max(1, keepdim=True)[1].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TvjqLW0S0xc"
   },
   "outputs": [],
   "source": [
    "fashion_labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \r\n",
    "                  \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \r\n",
    "                  \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SV07wsuMcwiz"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\r\n",
    "for i in range(6):\r\n",
    "    plt.subplot(2,3,i+1)\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\r\n",
    "    plt.title(\"Predicted: {}\".format(fashion_labels[predicted_labels[i][0]]))\r\n",
    "    plt.xticks([])\r\n",
    "    plt.yticks([])\r\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise - Classification CNN Hands on.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
