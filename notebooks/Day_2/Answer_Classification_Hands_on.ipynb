{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answer - Classification Hands on.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5OW4csoRjXr"
      },
      "source": [
        "# Part 2 - Classification with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WcjqDImRf87"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import torchvision\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10LsEe7QhMRP"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e051WsvWPb9k"
      },
      "source": [
        "device = 'cuda'\r\n",
        "n_epochs = 10\r\n",
        "batch_size_train = 128\r\n",
        "batch_size_test = 32\r\n",
        "learning_rate = 0.00001\r\n",
        "momentum = 0.9"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beixi1tJOX2U"
      },
      "source": [
        "# Prepare CIFAR10 image dataset\r\n",
        "\r\n",
        "Using torchvision api to download MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFOUrJxwXsJi"
      },
      "source": [
        "transform = torchvision.transforms.Compose([\r\n",
        "        torchvision.transforms.ToTensor()\r\n",
        "    ])\r\n",
        "\r\n",
        "train_data = torchvision.datasets.FashionMNIST('./data', train=True, download=True,\r\n",
        "                                       transform=transform)\r\n",
        "validation_data = torchvision.datasets.FashionMNIST('./data', train=False, download=True,\r\n",
        "                                      transform=transform)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size_train, \r\n",
        "                                           shuffle=True)\r\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size_test, \r\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQaNIp60ObkF"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQrG4ScyYtoo"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "\r\n",
        "        self.fc1 = nn.Linear(784, 256)\r\n",
        "        self.fc2 = nn.Linear(256, 50)\r\n",
        "        self.fc3 = nn.Linear(50, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MhwUtzyOWgY"
      },
      "source": [
        "# Initialize model and send to GPU\r\n",
        "network = Net().to(device)\r\n",
        "\r\n",
        "# Set algorithm for parameter update\r\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_F7M1hJOeDy"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnBwAdMxZ6Mu"
      },
      "source": [
        "# Almost the same format with training loop.\r\n",
        "# But, without .backward(), .step()\r\n",
        "# Also using different data loader.\r\n",
        "def evaluate():\r\n",
        "    network.eval()\r\n",
        "    val_loss, correct = 0, 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data, target in validation_loader:\r\n",
        "            data, target = data.to(device), target.to(device)\r\n",
        "            data = data.view(data.shape[0], -1)\r\n",
        "            output = network(data)\r\n",
        "            val_loss += F.nll_loss(output, target, size_average=False).item() \r\n",
        "            \r\n",
        "            pred = output.data.max(1, keepdim=True)[1]\r\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\r\n",
        "    val_loss /= len(validation_loader.dataset)\r\n",
        "    val_losses.append(val_loss)\r\n",
        "    print('\\nValidation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\r\n",
        "        val_loss, correct, len(validation_loader.dataset),\r\n",
        "        100. * correct / len(validation_loader.dataset)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX3w9Vo-EhBs",
        "outputId": "0c41a248-32c2-4b5e-ed08-d9063b8a2ff6"
      },
      "source": [
        "network"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=50, bias=True)\n",
              "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwQGFw0-1JLn"
      },
      "source": [
        "train_losses, train_counter, val_losses = [], [], []"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQttClGbaOrh",
        "outputId": "0fb8f2cc-fd38-4fbe-90b5-6f72dbadfc11"
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\r\n",
        "\r\n",
        "    # Print training loss for every 10 batch\r\n",
        "    log_interval = 10\r\n",
        "\r\n",
        "    # Set model to training mode\r\n",
        "    # Change behavior of some layers like batchnorm, dropout, etc\r\n",
        "    network.train()\r\n",
        "\r\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\r\n",
        "\r\n",
        "        # Send tensor to specified device\r\n",
        "        # Default on CPU\r\n",
        "        # Sending them to GPU OR CUDA\r\n",
        "        data, target = data.to(device), target.to(device)\r\n",
        "\r\n",
        "        # Reset all gradient to zero after each iteration\r\n",
        "        # To prevent gradient accumulation\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # # Change shape of input data to fit format of fully connected\r\n",
        "        data = data.view(data.shape[0], -1)\r\n",
        "\r\n",
        "        # Forward pass\r\n",
        "        output = network(data)\r\n",
        "        # Loss Calculation\r\n",
        "        loss = F.nll_loss(output, target)\r\n",
        "\r\n",
        "        # Calculate the update value for every parameters\r\n",
        "        # Does not update parameter value\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # Update all parameters according to the gradient value\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        # Print training loss\r\n",
        "        if batch_idx % log_interval == 0:\r\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\r\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\r\n",
        "            train_losses.append(loss.item())\r\n",
        "            train_counter.append(\r\n",
        "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\r\n",
        "\r\n",
        "    # Perform evaluation\r\n",
        "    evaluate()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307971\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.311948\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.301674\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.303104\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.310769\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.310230\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.308967\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.298877\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.305055\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.301081\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.315619\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.294065\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.302971\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.301956\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.300116\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.306979\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.307964\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.297075\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.303263\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.306002\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.302915\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.308713\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.307810\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.300412\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.305511\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.305371\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.313888\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.294142\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.299606\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.292974\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.307653\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.302752\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.309660\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 2.305691\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 2.304831\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.307751\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.302273\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.288604\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.293833\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.306961\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.308228\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 2.294253\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.299237\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 2.306149\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 2.299141\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.300229\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 2.296932\n",
            "\n",
            "Validation set: Avg. loss: 2.3012, Accuracy: 1015/10000 (10%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.308709\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 2.306744\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 2.301608\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 2.305284\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 2.296565\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.307295\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 2.301610\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 2.292179\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 2.301466\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 2.305003\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.300545\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 2.295231\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 2.296084\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 2.298564\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 2.297179\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 2.298526\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 2.294024\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 2.291492\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 2.297868\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 2.289521\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.293033\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 2.291442\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 2.290585\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 2.298406\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 2.298363\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.294731\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 2.305335\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 2.290770\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 2.300538\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 2.302444\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.294370\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 2.289013\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 2.299855\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 2.305528\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 2.302189\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 2.290358\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 2.285601\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 2.300275\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 2.299168\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 2.298348\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.303078\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 2.298062\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 2.302855\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 2.305435\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 2.295456\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 2.303539\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 2.294650\n",
            "\n",
            "Validation set: Avg. loss: 2.2969, Accuracy: 1049/10000 (10%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.297536\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 2.303015\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 2.302020\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 2.296525\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 2.294647\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 2.288365\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 2.301891\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 2.297693\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 2.302259\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 2.296542\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.298643\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 2.303846\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 2.296290\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 2.289178\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 2.311646\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 2.284792\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 2.305647\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 2.296443\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 2.301505\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 2.291704\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.300464\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 2.296396\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 2.300790\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 2.290543\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 2.306269\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.299135\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 2.298052\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 2.293166\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 2.283113\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 2.294223\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.288188\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 2.295634\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 2.291347\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 2.288093\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 2.296196\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 2.292110\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 2.300358\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 2.297795\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 2.287042\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 2.292881\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.297979\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 2.291400\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 2.290564\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 2.285944\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 2.295881\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 2.301872\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 2.294660\n",
            "\n",
            "Validation set: Avg. loss: 2.2928, Accuracy: 1123/10000 (11%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.288641\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 2.294910\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 2.302700\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 2.294872\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 2.292714\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 2.298929\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 2.287251\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 2.285387\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 2.302000\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 2.293524\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.280760\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 2.283078\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 2.294412\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 2.283872\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 2.293694\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 2.278446\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 2.295837\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 2.284478\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 2.281281\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 2.288449\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.294438\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 2.286654\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 2.291937\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 2.291010\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 2.286405\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.286384\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 2.296084\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 2.290450\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 2.296169\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 2.291228\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.282093\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 2.293088\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 2.295701\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 2.288154\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 2.279267\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 2.282830\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 2.278975\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 2.294265\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 2.289130\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 2.301968\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.288801\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 2.280495\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 2.297147\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 2.284307\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 2.288537\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 2.291072\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 2.287426\n",
            "\n",
            "Validation set: Avg. loss: 2.2889, Accuracy: 1228/10000 (12%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.298326\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 2.288369\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 2.287887\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 2.284948\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 2.283366\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 2.285267\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 2.289684\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 2.278445\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 2.274787\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 2.295823\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 2.294514\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 2.298741\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 2.283937\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 2.287562\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 2.289737\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 2.290916\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 2.288911\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 2.284405\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 2.284481\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 2.283359\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 2.288154\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 2.292268\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 2.278783\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 2.284787\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 2.297900\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.287423\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 2.287061\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 2.280081\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 2.293729\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 2.290132\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 2.286061\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 2.276232\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 2.286674\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 2.282809\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 2.281494\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 2.287445\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 2.278518\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 2.284937\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 2.286997\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 2.293261\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.282647\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 2.278525\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 2.291679\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 2.282049\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 2.280940\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 2.288453\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 2.284756\n",
            "\n",
            "Validation set: Avg. loss: 2.2850, Accuracy: 1366/10000 (14%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.285373\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 2.281081\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 2.280546\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 2.286826\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 2.295190\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 2.279879\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 2.284402\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 2.285576\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 2.289044\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 2.287750\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 2.276156\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 2.285489\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 2.283904\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 2.292451\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 2.287047\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 2.291029\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 2.286159\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 2.277383\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 2.286758\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 2.275160\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 2.282817\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 2.288969\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 2.289513\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 2.281215\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 2.277485\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 2.285766\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 2.267216\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 2.281596\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 2.292142\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 2.284741\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 2.285582\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 2.279765\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 2.282902\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 2.286369\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 2.275970\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 2.274593\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 2.269580\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 2.277701\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 2.276464\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 2.279668\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 2.278815\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 2.274436\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 2.277142\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 2.282200\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 2.276569\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 2.276527\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 2.280058\n",
            "\n",
            "Validation set: Avg. loss: 2.2813, Accuracy: 1553/10000 (16%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.284548\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 2.281543\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 2.276816\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 2.285549\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 2.277634\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 2.289569\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 2.270801\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 2.276161\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 2.278779\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 2.280304\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 2.279251\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 2.284853\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 2.289081\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 2.284464\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 2.285401\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 2.288320\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 2.277915\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 2.284595\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 2.280151\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 2.292686\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 2.278025\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 2.288893\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 2.280973\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 2.278277\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 2.277657\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 2.280135\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 2.271435\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 2.281871\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 2.274633\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 2.284986\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 2.285698\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 2.277517\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 2.277141\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 2.275877\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 2.268675\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 2.282450\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 2.275351\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 2.275352\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 2.286524\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 2.278100\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 2.274343\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 2.276861\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 2.272256\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 2.285286\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 2.276115\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 2.269794\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 2.272907\n",
            "\n",
            "Validation set: Avg. loss: 2.2776, Accuracy: 1782/10000 (18%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.284039\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 2.274042\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 2.279853\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 2.271631\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 2.284319\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 2.277684\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 2.281777\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 2.278071\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 2.276197\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 2.287847\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 2.291812\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 2.272358\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 2.287498\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 2.280452\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 2.280676\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 2.275944\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 2.268090\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 2.268386\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 2.274143\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 2.274958\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 2.278115\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 2.268434\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 2.276168\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 2.279611\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 2.278697\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 2.281058\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 2.281886\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 2.270721\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 2.271163\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 2.277161\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 2.281291\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 2.282644\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 2.280029\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 2.268667\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 2.265341\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 2.280678\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 2.285223\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 2.277816\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 2.278728\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 2.268961\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 2.270977\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 2.269511\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 2.273464\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 2.286337\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 2.277376\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 2.278412\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 2.284059\n",
            "\n",
            "Validation set: Avg. loss: 2.2739, Accuracy: 1998/10000 (20%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.272284\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 2.267675\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 2.269770\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 2.270994\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 2.263817\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 2.264369\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 2.276542\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 2.267894\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 2.274532\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 2.271541\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 2.272013\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 2.275445\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 2.256734\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 2.269518\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 2.280279\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 2.278285\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 2.277754\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 2.272491\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 2.275954\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 2.269458\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 2.270244\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 2.272175\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 2.275833\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 2.274446\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 2.274800\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.271402\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 2.273918\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 2.271170\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 2.264594\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 2.270037\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 2.276289\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 2.279625\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 2.263465\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 2.267705\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 2.262313\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 2.268621\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 2.269976\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 2.272675\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 2.267025\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 2.262372\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 2.270963\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 2.261596\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 2.268692\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 2.274029\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 2.264913\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 2.270834\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 2.265222\n",
            "\n",
            "Validation set: Avg. loss: 2.2702, Accuracy: 2178/10000 (22%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.273594\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 2.263434\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 2.279997\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 2.287422\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 2.266033\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 2.270143\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 2.272985\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 2.274052\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 2.273462\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 2.275812\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 2.266565\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 2.273726\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 2.270683\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 2.258279\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 2.255648\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 2.270854\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 2.268568\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 2.270444\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 2.265362\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 2.259362\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 2.270087\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 2.269326\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 2.274350\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 2.263388\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 2.269244\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 2.267202\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 2.264728\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 2.267796\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 2.271044\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 2.255630\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 2.265775\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 2.257239\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 2.259717\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 2.263672\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 2.269475\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 2.267345\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 2.265585\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 2.269662\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 2.276989\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 2.262456\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 2.269595\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 2.277807\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 2.259763\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 2.269238\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 2.263295\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 2.265934\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 2.257486\n",
            "\n",
            "Validation set: Avg. loss: 2.2664, Accuracy: 2346/10000 (23%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r93dTMK3PM4r"
      },
      "source": [
        "# View Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5MByWx0aUJ6"
      },
      "source": [
        "# Evaluate on one batch only\r\n",
        "examples = enumerate(validation_loader)\r\n",
        "batch_idx, (example_data, example_targets) = next(examples)\r\n",
        "\r\n",
        "# To run model without performing grading parameters\r\n",
        "with torch.no_grad():\r\n",
        "\r\n",
        "    # Prepare dataset\r\n",
        "    pred_data = example_data\r\n",
        "    pred_data = pred_data.view(pred_data.shape[0], -1)\r\n",
        "\r\n",
        "    # Set model to evaluation mode\r\n",
        "    network.eval()\r\n",
        "\r\n",
        "    # Inference\r\n",
        "    predictions = network(pred_data.to(device))\r\n",
        "\r\n",
        "    # Format predictions to get labels\r\n",
        "    predicted_labels = predictions.data.max(1, keepdim=True)[1].cpu().detach().numpy()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TvjqLW0S0xc"
      },
      "source": [
        "fashion_labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \r\n",
        "                  \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \r\n",
        "                  \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "SV07wsuMcwiz",
        "outputId": "7716a4f7-651c-44cb-adf5-09070af62892"
      },
      "source": [
        "fig = plt.figure()\r\n",
        "for i in range(6):\r\n",
        "    plt.subplot(2,3,i+1)\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\r\n",
        "    plt.title(\"Predicted: {}\".format(fashion_labels[predicted_labels[i][0]]))\r\n",
        "    plt.xticks([])\r\n",
        "    plt.yticks([])\r\n",
        "fig"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u-cIpPrSyve"
      },
      "source": [
        "### View model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN_tmEVqS5-G",
        "outputId": "3c66bc66-6c91-4f60-a8ad-59fda4cdcc4f"
      },
      "source": [
        "for name, param in network.state_dict().items():\r\n",
        "    print(\"Layer: \", name)\r\n",
        "    print(param)\r\n",
        "    print()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer:  fc1.weight\n",
            "tensor([[-0.0220,  0.0267,  0.0058,  ...,  0.0053,  0.0197,  0.0253],\n",
            "        [-0.0257,  0.0068,  0.0118,  ..., -0.0248,  0.0301,  0.0024],\n",
            "        [ 0.0258,  0.0356, -0.0192,  ..., -0.0297, -0.0321,  0.0260],\n",
            "        ...,\n",
            "        [ 0.0116, -0.0100,  0.0156,  ..., -0.0201,  0.0225, -0.0202],\n",
            "        [-0.0277,  0.0351, -0.0347,  ...,  0.0201,  0.0031, -0.0275],\n",
            "        [-0.0205,  0.0214, -0.0063,  ...,  0.0177, -0.0341,  0.0141]],\n",
            "       device='cuda:0')\n",
            "\n",
            "Layer:  fc1.bias\n",
            "tensor([-2.4285e-02,  3.3695e-02,  1.2884e-02,  3.5255e-02,  6.7548e-03,\n",
            "         1.9411e-02,  2.0017e-02,  2.7183e-02, -3.4434e-02,  8.9119e-03,\n",
            "         1.3121e-02,  1.2831e-02, -1.9941e-02,  3.3297e-02,  2.2363e-02,\n",
            "        -1.7562e-02, -1.6060e-02,  9.2808e-03,  3.1963e-02,  1.9685e-02,\n",
            "         7.5859e-03, -2.9045e-02, -5.3001e-03,  2.3263e-02, -2.2804e-02,\n",
            "         2.9957e-03, -7.2482e-03, -3.4849e-02,  4.6390e-03, -3.0335e-02,\n",
            "         7.3111e-04,  2.4710e-02, -1.4909e-03,  1.3794e-02, -1.3214e-02,\n",
            "         3.5493e-04,  3.5473e-02, -3.1887e-02,  2.5048e-02,  3.2956e-02,\n",
            "         8.5396e-03,  7.4622e-03,  1.4691e-02,  2.7296e-02, -1.2848e-02,\n",
            "         1.4582e-02,  6.2590e-03,  2.5947e-02,  1.3728e-02,  2.6582e-02,\n",
            "         1.9776e-02,  2.8280e-02,  2.6540e-02, -1.8554e-02, -3.0596e-02,\n",
            "        -6.3356e-03, -5.9092e-04,  1.9744e-02, -1.4554e-02,  3.9553e-03,\n",
            "        -3.4459e-02, -1.3704e-02,  2.8110e-02,  3.1974e-02,  3.3620e-02,\n",
            "        -2.4540e-02, -2.0291e-02, -2.7129e-02, -2.3106e-02, -2.3594e-02,\n",
            "        -7.3610e-03, -8.5807e-03,  1.8550e-02, -2.7169e-02, -9.8479e-03,\n",
            "        -3.5107e-02, -2.9261e-02, -8.9943e-04,  1.7629e-02,  2.7813e-02,\n",
            "        -1.3526e-02,  2.3959e-02, -1.6945e-02,  1.3918e-02, -9.4337e-03,\n",
            "        -3.1879e-02, -2.3983e-03,  4.9505e-03, -1.6805e-02, -1.0387e-02,\n",
            "        -2.6394e-02,  2.5190e-04,  1.8529e-02,  1.7660e-02, -3.9342e-03,\n",
            "         2.1669e-02,  3.0153e-02,  2.5173e-02,  2.5255e-02,  1.6229e-02,\n",
            "         1.3417e-02,  1.4257e-02,  1.9039e-02,  3.1557e-02, -1.2706e-02,\n",
            "         2.4350e-02,  1.0359e-02,  2.2094e-02,  2.8992e-02,  3.4756e-02,\n",
            "         1.8236e-02, -6.7019e-03, -1.5087e-02,  1.2523e-02,  8.4139e-03,\n",
            "        -2.5969e-02,  1.9382e-02, -1.1190e-02, -2.0009e-02, -2.2435e-02,\n",
            "         2.8929e-02, -3.3436e-02,  8.0851e-03,  2.6518e-02, -3.5470e-02,\n",
            "        -3.4590e-02,  2.8135e-02,  8.5971e-03, -1.2850e-02,  1.9824e-02,\n",
            "         2.3824e-02,  1.8149e-02,  6.8035e-03,  3.2534e-02,  3.2146e-02,\n",
            "        -1.5082e-02, -1.2536e-02, -1.1774e-03,  2.1222e-03,  1.7811e-02,\n",
            "        -2.4458e-02, -2.9814e-02, -3.1071e-02,  2.3878e-02,  1.3834e-02,\n",
            "         1.9995e-02, -1.6727e-02, -1.7640e-03, -3.0336e-03, -3.5066e-02,\n",
            "         2.8741e-02, -3.3719e-02, -2.3744e-02, -2.9363e-02, -1.5554e-02,\n",
            "         8.9183e-03, -2.7458e-02,  2.9733e-02,  2.4672e-02, -1.0831e-02,\n",
            "         1.7334e-02,  9.6463e-03, -2.6935e-02, -1.0962e-02, -3.2612e-02,\n",
            "        -9.3754e-03, -6.7237e-03, -1.5868e-02, -3.4278e-02, -2.3522e-02,\n",
            "         1.6268e-02, -3.3209e-02,  1.1785e-02,  7.0886e-03,  2.8874e-02,\n",
            "         9.1537e-04,  1.3023e-02,  9.0481e-03,  1.4660e-02, -3.1377e-02,\n",
            "         2.4206e-02,  1.4858e-04, -6.2692e-03,  8.5483e-03,  9.0678e-03,\n",
            "        -1.9916e-02, -2.7256e-02, -1.8491e-03, -1.5118e-03, -3.5019e-02,\n",
            "         1.6162e-03,  2.6566e-02,  2.7245e-02,  3.4831e-02,  3.2741e-03,\n",
            "         3.3782e-02, -2.5653e-02,  2.3174e-02, -1.3465e-02,  3.0697e-02,\n",
            "         2.8133e-02,  3.1699e-03,  2.6209e-02,  1.0258e-02,  2.5824e-02,\n",
            "         1.0699e-02, -1.3387e-02,  2.6926e-03, -4.1257e-03,  8.3541e-03,\n",
            "         1.5816e-03,  6.1510e-03, -1.5170e-02,  2.2122e-02, -3.4778e-02,\n",
            "         1.2379e-02, -1.0102e-02,  9.4564e-03, -1.5998e-02, -8.0232e-05,\n",
            "        -5.9758e-03, -2.4918e-02,  2.1013e-02, -5.3720e-03,  1.9149e-02,\n",
            "         2.6112e-02, -1.5845e-02,  2.2959e-02, -5.0461e-03,  2.7292e-02,\n",
            "        -1.1392e-02, -2.8491e-03, -1.1799e-02,  3.1574e-02, -3.1541e-02,\n",
            "         3.1352e-02, -5.0600e-03, -1.2885e-03,  1.2207e-03,  1.0570e-02,\n",
            "        -2.4853e-02,  2.9607e-02,  2.1084e-02, -1.8210e-02, -2.7513e-02,\n",
            "         3.1399e-03, -1.0243e-02,  2.0803e-02,  1.3425e-02,  2.8725e-02,\n",
            "        -7.7936e-04,  9.8197e-03,  3.4979e-02,  1.9154e-02,  1.5447e-02,\n",
            "        -1.6727e-02], device='cuda:0')\n",
            "\n",
            "Layer:  fc2.weight\n",
            "tensor([[-0.0078,  0.0113,  0.0103,  ..., -0.0087,  0.0592,  0.0028],\n",
            "        [ 0.0435, -0.0449,  0.0004,  ..., -0.0526, -0.0209, -0.0372],\n",
            "        [ 0.0094, -0.0274, -0.0223,  ..., -0.0215,  0.0223, -0.0522],\n",
            "        ...,\n",
            "        [ 0.0489,  0.0111, -0.0139,  ..., -0.0561, -0.0373,  0.0171],\n",
            "        [ 0.0383,  0.0097,  0.0389,  ...,  0.0161, -0.0279, -0.0381],\n",
            "        [-0.0398, -0.0082,  0.0433,  ...,  0.0073, -0.0246,  0.0570]],\n",
            "       device='cuda:0')\n",
            "\n",
            "Layer:  fc2.bias\n",
            "tensor([-0.0152, -0.0043,  0.0597, -0.0346, -0.0461, -0.0435, -0.0034,  0.0369,\n",
            "        -0.0070, -0.0294, -0.0187,  0.0182,  0.0248,  0.0421,  0.0374,  0.0165,\n",
            "        -0.0005, -0.0256, -0.0257, -0.0489,  0.0450, -0.0515,  0.0085,  0.0069,\n",
            "         0.0382,  0.0038, -0.0497, -0.0466, -0.0569, -0.0484, -0.0056,  0.0279,\n",
            "        -0.0320, -0.0536, -0.0380, -0.0236, -0.0142,  0.0322, -0.0565,  0.0543,\n",
            "        -0.0387,  0.0149, -0.0303, -0.0193,  0.0004, -0.0419, -0.0078,  0.0237,\n",
            "        -0.0434, -0.0164], device='cuda:0')\n",
            "\n",
            "Layer:  fc3.weight\n",
            "tensor([[ 9.0224e-02, -8.7495e-02, -9.0213e-02,  1.8634e-02, -1.1467e-01,\n",
            "         -7.3145e-02,  7.1957e-02,  9.0475e-02,  3.1503e-02,  1.1229e-01,\n",
            "         -7.2283e-02, -9.5967e-02, -9.5251e-02, -1.3855e-01, -6.2819e-02,\n",
            "         -1.3860e-02, -1.1389e-02,  5.8868e-02, -9.1383e-02,  1.1197e-01,\n",
            "         -5.1865e-02, -1.2632e-01, -1.8842e-02, -4.6558e-03, -5.0922e-02,\n",
            "          4.0648e-02,  5.1096e-02,  9.4345e-02, -1.2285e-01, -2.1382e-02,\n",
            "         -1.8048e-02, -5.0021e-02, -3.6718e-03, -4.6875e-02, -6.0420e-03,\n",
            "          3.0557e-02,  9.4508e-02, -1.8823e-02, -3.1750e-02, -4.4496e-02,\n",
            "         -1.0777e-01, -7.6365e-02,  5.5917e-02, -6.9603e-02, -8.1787e-02,\n",
            "         -2.9547e-02, -1.2581e-01,  1.3555e-02,  1.2554e-01,  6.2194e-03],\n",
            "        [ 5.6841e-02, -3.2444e-02,  7.0666e-03,  6.3179e-02, -1.1839e-01,\n",
            "         -5.0724e-02,  5.6883e-04, -1.2469e-01,  1.3844e-01,  5.1236e-02,\n",
            "         -9.9201e-02, -4.1159e-03,  3.9633e-04,  9.7247e-02,  4.0970e-03,\n",
            "          1.1109e-02, -2.7730e-02, -8.7878e-02, -3.0181e-02,  1.0995e-01,\n",
            "         -1.1266e-01,  6.8539e-03, -5.4560e-02,  1.2522e-01,  6.3697e-02,\n",
            "          1.6489e-02, -6.1105e-02,  6.9372e-02,  6.1280e-02,  7.0276e-02,\n",
            "         -7.7851e-02,  1.0390e-01, -1.0129e-01,  3.4998e-04,  5.6147e-02,\n",
            "         -1.0699e-01, -2.8898e-02, -1.8160e-02,  6.1735e-02,  3.7169e-03,\n",
            "         -9.2357e-02, -7.0875e-02, -8.5312e-02,  4.6213e-02, -9.9956e-02,\n",
            "         -1.3070e-01, -8.9911e-02, -1.2348e-01, -6.5676e-02, -7.3055e-02],\n",
            "        [-5.5363e-02,  1.1286e-01,  1.2442e-01, -5.6585e-02,  9.0106e-03,\n",
            "          9.5769e-02, -3.0074e-02, -6.7154e-02, -1.0792e-01,  1.0909e-01,\n",
            "         -2.5061e-02,  1.6871e-02,  1.6941e-02,  1.3402e-01, -4.7395e-02,\n",
            "          4.1915e-02,  7.1202e-02, -8.9445e-02, -7.6706e-02,  7.3508e-02,\n",
            "          8.6449e-02,  1.1106e-02, -6.0600e-02,  5.9289e-02, -6.5905e-02,\n",
            "         -1.2013e-01,  1.3313e-01, -7.9838e-02, -1.3551e-01,  5.4983e-02,\n",
            "         -5.4939e-02, -1.9367e-02, -1.0371e-01,  9.8959e-02,  9.2171e-02,\n",
            "          7.7096e-02,  1.0310e-01, -8.0289e-02,  1.1019e-01,  1.3190e-01,\n",
            "         -3.0443e-02, -3.3347e-03, -1.3137e-01, -1.2051e-01,  1.1634e-01,\n",
            "         -7.8115e-02, -9.2295e-02,  1.3103e-01,  8.3552e-02,  1.7801e-02],\n",
            "        [ 7.4752e-02,  1.1055e-01, -6.9138e-02,  1.9072e-02, -7.9661e-02,\n",
            "          8.9398e-03,  3.7595e-02,  1.1173e-01, -2.0735e-02, -1.2273e-01,\n",
            "         -8.6934e-03, -3.7226e-02, -1.5512e-02, -6.0247e-02, -1.1348e-01,\n",
            "          3.1045e-02,  5.1867e-02, -1.2358e-01, -1.3287e-02,  2.1086e-03,\n",
            "         -3.6164e-02,  2.0064e-02,  6.8624e-02,  6.7579e-03, -1.0659e-01,\n",
            "          1.3164e-01,  8.1444e-02,  7.0826e-02,  1.2480e-01,  1.0070e-02,\n",
            "         -1.2253e-01,  9.3267e-03, -4.2488e-03,  1.0271e-01,  5.3356e-02,\n",
            "         -1.1163e-02, -7.6020e-02, -1.2193e-01, -1.1054e-01, -8.1119e-02,\n",
            "         -1.3552e-01,  4.6244e-02, -1.0987e-01,  3.1669e-03,  1.4022e-01,\n",
            "          1.9055e-02, -7.4448e-02,  6.3411e-02,  8.3138e-02, -7.6235e-02],\n",
            "        [-3.8424e-02, -1.0075e-01, -9.0764e-02,  4.6451e-02,  1.1951e-01,\n",
            "          1.2284e-01,  4.4179e-02, -8.8225e-02,  9.0270e-02, -7.4343e-03,\n",
            "          3.4516e-02,  4.9321e-02, -1.2001e-01,  1.1240e-01, -1.3818e-01,\n",
            "         -9.4778e-02,  1.1379e-01,  8.2980e-02, -9.5213e-02,  8.8011e-02,\n",
            "         -1.5673e-02,  3.8633e-02, -1.3942e-01, -1.0470e-01, -8.6897e-02,\n",
            "          1.7875e-02, -2.1229e-02, -4.5979e-03,  1.2326e-01, -2.9607e-02,\n",
            "         -9.9585e-02, -9.7113e-02,  1.2744e-01,  9.4552e-02, -1.6236e-02,\n",
            "         -1.2302e-01, -3.4463e-02, -6.4803e-02,  8.3043e-02,  4.6390e-02,\n",
            "          1.2505e-01,  1.0205e-01, -3.3269e-02, -8.3739e-02, -1.8873e-02,\n",
            "          7.9375e-02, -1.1844e-01,  7.0312e-02, -7.5517e-05, -9.0193e-02],\n",
            "        [-1.3636e-02,  1.1428e-01,  4.0836e-02,  4.8971e-02, -1.3109e-01,\n",
            "          3.7509e-02, -1.2456e-01,  6.8001e-02, -6.2189e-02,  1.3762e-01,\n",
            "          8.2206e-02,  1.2899e-02,  4.2232e-02, -4.0303e-03,  1.2244e-01,\n",
            "         -5.5065e-04,  1.2936e-02,  6.5905e-02, -1.0264e-02, -1.0065e-01,\n",
            "          2.4849e-02, -8.5626e-02, -1.0287e-01,  1.2055e-02, -1.4024e-01,\n",
            "          5.0594e-02, -1.2225e-01,  9.2906e-02, -7.3614e-03, -1.7304e-03,\n",
            "         -4.6248e-02, -3.9322e-02,  6.5808e-02,  9.6056e-02,  1.2148e-01,\n",
            "          5.9642e-02,  1.4197e-02, -4.8677e-02, -9.8654e-02, -6.4505e-02,\n",
            "          1.7554e-02,  7.1879e-02, -3.6475e-02, -1.0118e-01,  6.7232e-03,\n",
            "          1.2353e-01,  3.0131e-02,  1.9491e-02, -1.0330e-01, -7.0134e-02],\n",
            "        [-9.4603e-02,  6.9035e-02,  4.1525e-02, -8.8584e-03,  3.4628e-02,\n",
            "          4.6808e-02,  1.1424e-01, -7.5581e-02,  5.7897e-02, -1.3904e-01,\n",
            "          3.5364e-03, -3.9768e-02, -7.7929e-02, -6.4138e-02, -1.1038e-01,\n",
            "          1.0366e-01,  1.0552e-01,  1.0614e-01, -1.3880e-01,  1.2448e-01,\n",
            "          9.5333e-02,  4.7199e-02,  6.0355e-02, -8.4492e-03,  1.8146e-02,\n",
            "         -1.0663e-01,  6.3146e-03,  1.2248e-01,  8.2398e-02,  6.5899e-02,\n",
            "         -3.3482e-03, -1.4106e-02,  3.5068e-02,  1.2889e-01,  9.6102e-02,\n",
            "         -1.3703e-01, -6.3222e-02,  4.3747e-02, -8.1129e-02,  5.7060e-03,\n",
            "          7.0224e-02,  5.8609e-02,  2.1980e-02, -8.8125e-03, -1.3734e-01,\n",
            "          1.3789e-01,  9.8433e-02,  8.0839e-02,  1.4106e-01,  4.5054e-02],\n",
            "        [-7.8830e-02,  9.4112e-02, -2.2419e-02, -1.4105e-01, -6.0799e-02,\n",
            "         -1.1846e-01,  1.0409e-01,  6.8971e-03, -2.7488e-02,  9.0616e-02,\n",
            "          4.1460e-02,  1.7409e-02,  1.3279e-01, -1.1310e-01,  6.7276e-02,\n",
            "          4.7888e-02, -7.8060e-02,  8.7727e-02,  4.4307e-02,  4.1170e-02,\n",
            "          6.4196e-02,  4.0020e-02,  4.9099e-02, -7.5192e-02, -3.7924e-02,\n",
            "          1.1741e-01, -5.9160e-03,  8.4762e-02, -5.8311e-02, -2.7093e-02,\n",
            "          6.8930e-02,  1.2113e-01,  1.1856e-01,  4.1180e-02, -9.9058e-02,\n",
            "          3.1310e-02, -1.0183e-02,  1.2714e-01, -4.1720e-02,  6.8094e-02,\n",
            "          3.5793e-02, -1.1801e-01,  6.4435e-02,  9.9335e-02, -1.3589e-01,\n",
            "          7.4153e-02, -8.9496e-02, -6.0928e-02,  6.4470e-02,  8.1946e-02],\n",
            "        [-7.7061e-02,  5.7371e-02,  3.7630e-02, -8.8456e-03,  7.4064e-02,\n",
            "         -7.4688e-02, -1.9742e-02,  1.3652e-02,  1.1467e-02,  4.5501e-02,\n",
            "         -3.0258e-02,  2.5447e-02, -7.7072e-02,  3.0802e-02, -1.2713e-01,\n",
            "         -1.0829e-01,  1.1646e-01,  1.4426e-01, -1.2913e-01,  2.5094e-02,\n",
            "         -3.7695e-02,  1.1802e-01,  1.0454e-01,  3.2579e-02, -1.1078e-01,\n",
            "         -8.4959e-02,  9.7672e-02,  1.2691e-01,  7.9846e-02, -6.2310e-02,\n",
            "          7.8130e-02, -9.8115e-02,  1.3206e-01,  2.2314e-02, -7.5778e-02,\n",
            "         -5.5074e-03,  5.4931e-02,  3.8842e-02,  7.4170e-02, -8.8752e-02,\n",
            "         -8.5303e-02,  1.0437e-01, -1.3357e-01, -8.8023e-02,  1.0447e-01,\n",
            "          1.3329e-01, -1.0684e-01, -1.0641e-01, -4.6370e-02,  8.5219e-02],\n",
            "        [-3.9457e-02, -1.1927e-01, -3.8592e-02,  5.8401e-02,  1.0190e-01,\n",
            "          1.0462e-01, -4.3293e-02, -1.2099e-01,  1.3793e-01, -1.1862e-01,\n",
            "          1.0213e-01,  5.8008e-02,  1.2133e-02,  2.5254e-02, -1.1108e-01,\n",
            "          1.3508e-01, -2.9312e-02,  1.1599e-01, -2.6586e-02,  4.5581e-02,\n",
            "          3.6310e-02, -1.1847e-01,  4.8067e-02,  3.5541e-02, -6.1408e-03,\n",
            "          1.3327e-01,  5.8424e-02, -1.0490e-01, -1.2029e-01, -8.5742e-03,\n",
            "          1.2153e-02,  1.0966e-02, -9.3894e-02, -4.2027e-02, -1.1749e-01,\n",
            "          1.5695e-02,  7.5949e-02, -4.7688e-02,  1.0241e-01,  4.5880e-02,\n",
            "          1.0096e-01,  1.3520e-01,  1.1897e-01,  9.2908e-02, -9.4552e-04,\n",
            "          6.4975e-02,  5.7798e-02,  1.0504e-01, -1.2981e-01,  3.3343e-02]],\n",
            "       device='cuda:0')\n",
            "\n",
            "Layer:  fc3.bias\n",
            "tensor([ 0.0873, -0.0071, -0.1353, -0.0614, -0.0313, -0.0132, -0.0208, -0.0872,\n",
            "        -0.0832, -0.0535], device='cuda:0')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofzrYdzqVAY4"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}